---
title: Parse, donâ€™t validate
authors: Alexis King
year: 2019
date: 2025-01-07 23:11
tags: [literature, type-check, compiler, functional-programming, refactoring]
---

To turn a [partial function](../202501082113.md) into a total function, one can
either weaken the [return type](../202206301938.md) or strengthen the argument
type.

Weakening the return type by introducing `Option` type is an easy solution, but
it still requires input validation, which leads to [code redundancy](../202206171004.md),
potentially incurs additional performance cost, and prone to error. Such ad-hoc
validation would lead to [Shotgun Parsing](../202501082147.md), running the risk
of acting upon a valid portion of an input, discovering a different portion is
invalid, and suddenly have to roll back the modifications in place to maintain
consistency. And sometimes, such roll back would not be successful. Laborious
maintenance is needed to check if all validation is done up-front, and even with
that, some edge cases can still be missed.

The alternative, that is strengthening the argument type, has none of the
downsides, and it is trivial to revert to original signature. This approach
guarantees that there is always information returned from the function, either
in the form of formal type or error type. The author defines this as the
**parsing approach**, in which the function "consumes less-structured input and
produces more-structured output". It will terminate the program upon error.
Though, this comes with a drawback, which is more evident in dynamically-typed
#programming-language, where sometimes it is required for the value to be parsed
before being actually used.

To construct such function, the author suggests using the most precise data
structure that makes illegal states unrepresentable. The burden of proof should
be done at the boundary of the system, before any of the data is acted upon. In
short, "write functions on the data representation you wish you had".

King advices to let the data types inform the code, not the other way around.
Don't need to be afraid of parsing data in multiple passes, just don't act on
the input before it's fully parsed. Avoid denormalised representation of data,
especially if it is *mutable*. If denormalisation is necessary, encapsulate the
data to keep the representations in sync. If an illegal state is truly
unrepresentable, use abstract data types to make validators look like parsers.
