---
title: Parse, don’t validate
authors: Alexis King
year: 2019
date: 2025-01-07 23:11
tags: [literature, type-check, compiler, functional-programming, refactoring]
---

To turn a partial function into a total function, one can either weaken the
[return type](../202206301938.md) or strengthen the argument type.

**Note**: Partial function is a function that is not defined for all possible
inputs.

Weakening the return type by introducing `Option` type is an easy solution, but
it still requires input validation, which leads to [code
redundancy](../202206171004.md), potentially incurs additional performance cost,
and prone to error. Such ad-hoc validation would lead to *shotgun parsing*,
running the risk of acting upon a valid portion of an input, discovering a
different portion is invalid, and suddenly have to roll back the modifications
in place to maintain consistency. And sometimes, such roll back would not be
successful. Laborious maintenance is needed to check if all validation is done
up-front, and even with that, some edge cases can still be missed.

> Shotgun parsing is a programming antipattern whereby parsing and
> input-validating code is mixed with and spread across processing code—throwing
> a cloud of checks at the input, and hoping, without any systematic
> justification, that one or another would catch all the “bad” cases.

> Shotgun parsing necessarily deprives the program of the ability to reject
> invalid input instead of processing it. Late-discovered errors in an input
> stream will result in some portion of invalid input having been processed,
> with the consequence that program state is difficult to accurately predict.

The alternative, that is strengthening the argument type, has none of the
downsides, and it is trivial to revert to original signature. This approach
guarantees that there is always information returned from the function, either
in the form of formal type or error type. The author defines this as the
**parsing approach**, in which the function "consumes less-structured input and
produces more-structured output". It will terminate the program upon error.
Though, this comes with a drawback, which is more evident in dynamically-typed
#programming-language, where sometimes it is required for the value to be parsed
before being actually used.

To construct such function, the author suggests using the most precise data
structure that makes illegal states unrepresentable. The burden of proof should
be done at the boundary of the system, before any of the data is acted upon. In
short, "write functions on the data representation you wish you had".

King advices to let the data types inform the code, not the other way around.
Don't need to be afraid of parsing data in multiple passes, just don't act on
the input before it's fully parsed. Avoid denormalised representation of data,
especially if it is *mutable*. If denormalisation is necessary, encapsulate the
data to keep the representations in sync. If an illegal state is truly
unrepresentable, use abstract data types to make validators look like parser.
