---
tags: [networking, performance]
---

# TCP Congestion Control

Congestion control in TCP deploys addictive increase and multiplicative decrease
policy. It is done at the sender side (see [End-to-End Congestion Control](202304261438.md)).
Congestion is detected through loss event such as *timeout* or *three duplicate
ACKs* (4 ACKs). Sender keeps track of a variable, congestion window (`cwnd`),
which imposes a constraint on sending rate. Including [TCP Flow Control](202304231611.md),
the amount of unacknowledged data at the sender may not exceed the minimum of
congestion window and receiver window (`rwnd`), as stated in the following
equation:

$$
\text{last byte sent} - \text{last byte acked} \le \text{min}\{\text{cwnd}, \text{rwnd}\}
$$

Assuming that `rwnd` is extremely large, we can see that `cwnd` limits the
amount of unacknowledged data at the sender, which indirectly limits the sending
rate. Thus, the sender's send rate is roughly `cwnd`/RTT bytes/second. By
adjusting `cwnd` value, we can adjust the sending rate.

TCP has a **self-clocking** mechanism which can increase the transmit rate. This
is done by using the *ACK arrival rate* as indicator to increase the congestion
window's size accordingly.

To prevent the cases where TCP senders collectively send too fast or the link
bandwidth is under utilised, TCP adjusts its sending rate base on **lost
segment**, **acknowledged segment**, and **[bandwidth probing](202503192126.md)**.
Lost segment implies congestion, which TCP can reduce the sending rate. In
contrast, acknowledged segment implies well connection, and TCP can increase the
sending rate.

## Algorithm

TCP congestion control algorithm, as specified in RFC 5681, has three
components: *slow start*, *congestion avoidance*, and *fast recovery*. The
former two components are **mandatory**.

Sender first enters the slow-start state, initialises `cwnd` (congestion
window) as 1 [Maximum Segment Size (MSS)](202303282019.md), thus starts the
sending rate at 1 MSS/RTT. For each acknowledged packet, `cwnd` is increased
by 1 MSS. This will result in an *exponential* growth in sending rate. When a
timeout is indicated through loss event, the value of `cwnd` is reset to 1
MSS, a slow-start threshold is set to `cwnd`/2, and the slow-start process is
start over again. When `cwnd`'s value reaches the *slow-start threshold*, TCP
will enter congestion avoidance phase. If three duplicate ACKs (4 consecutive
ACKs) are detected, TCP will perform fast retransmission and enter fast recovery
phase.

During congestion avoidance, the sending rate is increased conservatively by
increasing it 1 MSS for every RTT. A common implementation is to increase
`cwnd` by 1 MSS/`cwnd` for each new ACK. When encountering a timeout event,
TCP behaves the same as in slow start phase. In the case of three duplicate
ACKs, the slow-start threshold is set to `cwnd`/2 and `cwnd` is halved and
added by 3 MSS (good measure in account for duplicate ACKs).

In fast recovery phase, `cwnd`'s value is increase by 1 MSS for each duplicate
ACK received for the missing segment. If an entirely new ACK packet has been
received, TCP will enter congestion avoidance phase. If a timeout event is
detected, slow start phase will be initiated instead, `cwnd` is reset to 1
MSS, and slow-start threshold is set to be half of the previous `cwnd`'s value.

In an idealistic assumption of a steady-state macroscopic dynamics of TCP in
which window size $W$ and round-trip time $RTT$ are approximately constant
over the connection duration, TCP transmission rate sits between
$\frac{W}{2 \times RTT}$ and $\frac{W}{RTT}$. It will go
through a recursive process, where the network drops a packet once the rate
increases to $\frac{W}{RTT}$, then proceed to congestion avoidance
phase by increasing the rate by $\frac{MSS}{RTT}$ every $RTT$. Thus,
we can get the ideal average throughput of the TCP connection:

$$
\text{Ideal average throughput of connection} = \frac{0.75 \times W}{RTT}
$$

To find the loss rate, we can derive from this formula and establish the
following formula:

$$
\text{Average throughput of connection} = \frac{1.22 \cdot MSS}{RTT \sqrt{L}}
$$

Where $L$ is the loss rate. In a [high-speed network](202303201846.md) era,
the current algorithm can't keep up with the needs since it tolerates very low
rate $L$ of packet loss probability of $2 \times 10^{-10}$, as proved by
the above formula. Moreover, both SS phase and connection establishment
contribute to the [Latency](202304111955.md) significantly especially when the
object size is relatively small and the RTT is relatively large (such as web)
which greatly affect the responsiveness.

- [TCP Tahoe Algorithm](202503212332.md)
- [TCP Reno Algorithm](202305031946.md)
- [TCP Vegas Algorithm](202305031935.md)
- [TCP CUBIC Algorithm](202504112215.md)
