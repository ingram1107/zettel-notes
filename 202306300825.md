---
tags: [performance, networking]
---

# Networking Fairness

Fairness in networking is defined as each connection getting equal share of link
bandwidth or the average rate of connection is roughly equal to the rate of
$\frac{R}{K}$ where $R$ is the transmission rate of the bottleneck
link and $K$ is the number of connections. However, due to the asymmetric
nature of end points' window sizes and protocols, some processes may get more
share on the bandwidth than the other. For example, the session with less
[Round-Trip Time (RTT)](202303292133.md) can acquire bandwidth more quickly
than those that with more RTT as it can open the congestion window faster than
the latter. Another example is [UDP](202206151759.md). It has an advantage
over [TCP](202206151232.md) in terms of fairness due to no [Network Congestion Control](202304261436.md)
are implemented in the protocol, thus no throttle will be done by the UDP in
sacrificing the performance of the TCP connections. If a process such as web
browser can open up several **parallel TCP connections**, it will have an
advantage over those that don't as it can get more link bandwidth allocated to
itself.
